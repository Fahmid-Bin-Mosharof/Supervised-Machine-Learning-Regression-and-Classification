# Classification with Logistic Regression

### Logistic Regression

Logistic regression is a classification algorithm used to predict binary outcomes (0 or 1, true or false). Unlike linear regression, it applies a non-linear transformation using the sigmoid function to restrict the output between 0 and 1.

It models the probability that a given input \( x \) belongs to class 1 using:

$$
h\_\theta(x) = \sigma(\theta^T x)
$$

---

### Sigmoid Function

The sigmoid function is the key to logistic regression. It maps any real-valued input to a value between 0 and 1.

$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$

Where:

- \( z = \theta^T x \)
- \( \sigma(z) \) represents the predicted probability of the positive class (label = 1)

---

### Decision Boundary

The decision boundary defines the region of the input space where the output label changes. For logistic regression, the decision boundary is the set of points where:

$$
\theta^T x = 0
$$

Predictions:

- If \( h\_\theta(x) \geq 0.5 \), predict class 1
- If \( h\_\theta(x) < 0.5 \), predict class 0

This boundary is linear if only linear terms are used in the hypothesis.

---

### Reference

This content is derived from Andrew Ngâ€™s Coursera course:  
[Supervised Machine Learning: Regression and Classification](https://www.coursera.org/learn/machine-learning)
